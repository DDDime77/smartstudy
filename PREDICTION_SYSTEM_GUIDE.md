# ğŸ§  VIVID & COMPREHENSIVE PREDICTION SYSTEM GUIDE

## ğŸ“– Table of Contents
1. [System Overview](#system-overview)
2. [The Prediction Pipeline](#the-prediction-pipeline)
3. [Real Scenarios with Actual Data](#real-scenarios-with-actual-data)
4. [Decision Tree Flowchart](#decision-tree-flowchart)
5. [Formulas & Calculations](#formulas--calculations)

---

## System Overview

The prediction system combines a **neural network ML model** with **adaptive rule-based adjustments** to predict:
- **Accuracy**: Probability the user will answer correctly (0-95%)
- **Time**: Expected seconds to complete the task (10-300s)

### Key Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ML Model      â”‚  â†’ Predicts based on user history + task embeddings
â”‚  (Neural Net)   â”‚     Output: base_prob, base_time
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Adaptive       â”‚  â†’ Applies rules based on recent performance
â”‚  Adjustment     â”‚     Output: adjusted_prob, adjusted_time
â”‚  Layer          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## The Prediction Pipeline

### STEP 1: Get ML Base Prediction
The neural network analyzes:
- User's historical performance
- Topic difficulty
- User's skill level in similar topics
- Time of day, task frequency patterns

**Output**: `base_prob` (accuracy %), `base_time` (seconds)

---

### STEP 2: Filter Relevant History
System retrieves user's history for the EXACT combination:
- Same **subject** (e.g., Math)
- Same **topic** (e.g., Calculus)
- Same **difficulty** (e.g., medium)

**Example**: If user has completed 50 Math tasks but only 12 are "Calculus medium", only those 12 are used.

---

### STEP 3: Calculate Performance Metrics
From relevant history, calculate:

```python
# Recent performance (last 5 tasks or all if < 5)
recent_success_rate = correct_count / recent_task_count
recent_avg_time = sum(actual_times) / recent_task_count

# Overall performance (all relevant tasks)
overall_success_rate = total_correct / total_tasks
overall_avg_time = sum(all_times) / total_tasks

# Improvement metrics
success_improvement = recent_success_rate - overall_success_rate
time_improvement = overall_avg_time - recent_avg_time  # Positive = getting faster

# Prediction deviation
prediction_error = base_time - recent_avg_time  # Positive = actual faster than predicted
```

---

### STEP 4: Apply Adaptive Adjustment Rules

The system follows a **hierarchy of rules** to adjust predictions:

#### ğŸ”¹ EARLY LEARNING (Tasks 1-3 for new topic)
**When**: `len(relevant_tasks) <= 3`

**Accuracy Mapping**:
```
recent_success_rate = 100%  â†’ adjusted_prob = 85%
recent_success_rate = 80%+  â†’ adjusted_prob = 75%
recent_success_rate = 60%+  â†’ adjusted_prob = 65%
recent_success_rate = 40%+  â†’ adjusted_prob = 50%
recent_success_rate = 20%+  â†’ adjusted_prob = 35%
recent_success_rate = 0%    â†’ adjusted_prob = 15%
```

**Time Calculation**:
```python
adjusted_time = recent_avg_time * 1.05  # 5% buffer
```

**Example**:
- Task 1: ML predicts 60s â†’ User completes in 30s
- Task 2: System predicts 30 * 1.05 = **32s** (ignores ML!)

---

#### ğŸ”¹ RULE 1: High Performance Boost
**When**: Tasks > 3

**Conditions**:
```python
if recent_success_rate > 0.8 AND success_improvement > 0.1:
    # User doing very well recently AND improving significantly
    boost_factor = 1.4 + (success_improvement * 0.8)
    adjusted_prob = min(0.95, base_prob * boost_factor)

elif success_improvement > 0.05:
    # User improving moderately
    boost_factor = 1.3 + (success_improvement * 0.5)
    adjusted_prob = min(0.95, base_prob * boost_factor)

elif recent_success_rate > 0.8:
    # Absolute high performance (even without improvement)
    adjusted_prob = min(0.95, max(0.80, base_prob * 1.2))

elif recent_success_rate > 0.7:
    # User doing well
    adjusted_prob = min(0.95, base_prob * 1.15)
```

---

#### ğŸ”¹ RULE 2: Poor Performance Reduction
**When**: Tasks > 3

**Conditions**:
```python
if recent_success_rate < 0.3 AND success_improvement < -0.1:
    # User struggling recently AND declining significantly
    reduction_factor = 0.8 + (success_improvement * 0.5)
    adjusted_prob = max(0.05, base_prob * reduction_factor)

elif success_improvement < -0.05:
    # User declining moderately
    reduction_factor = 0.9 + (success_improvement * 0.3)
    adjusted_prob = max(0.05, base_prob * reduction_factor)

elif recent_success_rate < 0.2:
    # Absolute poor performance (consistently failing)
    adjusted_prob = 0.15  # Floor

elif recent_success_rate < 0.4:
    # Below average performance
    adjusted_prob = max(0.25, base_prob * 0.7)
```

---

#### ğŸ”¹ RULE 3: Time Speed Adjustment
**When**: Tasks > 3

**Priority Order** (checks in sequence, first match wins):

**1. Time Improvement Check**:
```python
if time_improvement > 10:  # Getting faster by 10+ seconds
    time_factor = 0.9 - (min(time_improvement, 60) / 300)
    adjusted_time = max(10, base_time * time_factor)
    # Example: time_improvement=30s â†’ time_factor=0.8 â†’ reduce 20%

elif time_improvement < -10:  # Getting slower by 10+ seconds
    time_factor = 1.1 + (min(abs(time_improvement), 60) / 300)
    adjusted_time = min(300, base_time * time_factor)
    # Example: time_improvement=-30s â†’ time_factor=1.2 â†’ increase 20%
```

**2. Prediction Error Check (EXTREME deviation)**:
```python
elif prediction_error > 15:  # Actual faster than predicted
    if abs(prediction_error) / base_time > 1.0:  # Deviation > 100%
        # EXTREME: Use actual time directly
        adjusted_time = max(10, recent_avg_time * 1.05)
    else:
        # MODERATE: Blend ML and actual
        blend_factor = min(prediction_error / base_time, 0.5)
        adjusted_time = max(10, base_time * (1 - blend_factor))

elif prediction_error < -15:  # Actual slower than predicted
    if abs(prediction_error) / base_time > 1.0:  # Deviation > 100%
        # EXTREME: Use actual time directly
        adjusted_time = min(300, recent_avg_time * 1.05)
    else:
        # MODERATE: Blend ML and actual
        blend_factor = min(abs(prediction_error) / base_time, 0.5)
        adjusted_time = min(300, base_time * (1 + blend_factor))
```

**Example - Extreme Deviation**:
```
base_time = 60s
recent_avg_time = 150s
prediction_error = 60 - 150 = -90s (< -15 âœ“)
abs(-90) / 60 = 1.5 > 1.0 âœ“
â†’ adjusted_time = 150 * 1.05 = 158s
```

**Example - Moderate Deviation**:
```
base_time = 60s
recent_avg_time = 40s
prediction_error = 60 - 40 = 20s (> 15 âœ“)
20 / 60 = 0.33 < 1.0
blend_factor = 0.33
â†’ adjusted_time = 60 * (1 - 0.33) = 40s
```

---

#### ğŸ”¹ RULE 4: Constrain Unreasonable Predictions
**When**: `len(relevant_tasks) >= 10`

```python
if adjusted_prob < 0.30 AND overall_success_rate > 0.5:
    # ML too pessimistic
    adjusted_prob = max(0.5, overall_success_rate * 0.9)

elif adjusted_prob < 0.40 AND overall_success_rate > 0.6:
    # ML moderately pessimistic
    adjusted_prob = max(0.55, overall_success_rate * 0.85)

elif adjusted_prob > 0.85 AND overall_success_rate < 0.3:
    # ML too optimistic
    adjusted_prob = min(0.5, overall_success_rate * 1.2)
```

---

## Real Scenarios with Actual Data

### ğŸ“Š SCENARIO 1: New User (you3) - Mixed Performance
**Topic**: Differential Equations (medium) - **BRAND NEW TOPIC**

**User Pattern**: âœ“30s, âœ“45s, âœ—45s, âœ“30s

#### Task-by-Task Breakdown:

**TASK 1: First ever attempt**
```
â”Œâ”€ ML Prediction â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ No history â†’ Default prediction     â”‚
â”‚ base_prob = 50%                     â”‚
â”‚ base_time = 60s                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€ Adaptive Adjustment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ len(relevant_tasks) = 0             â”‚
â”‚ â†’ Skip adjustment (no data yet)     â”‚
â”‚ FINAL: Accuracy=50.0%, Time=60s     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
   User completes: âœ“ 30s
```

**TASK 2: First adaptation**
```
â”Œâ”€ ML Prediction â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ base_prob = 50%                     â”‚
â”‚ base_time = 60s (model not updated) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€ History Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ relevant_tasks = [Task 1: âœ“ 30s]   â”‚
â”‚ len = 1 â‰¤ 3 â†’ EARLY LEARNING!      â”‚
â”‚ recent_success_rate = 1/1 = 100%   â”‚
â”‚ recent_avg_time = 30s               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€ Early Learning Adjustment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ success_rate = 100% â†’ prob = 85%    â”‚
â”‚ time = 30 * 1.05 = 32s              â”‚
â”‚ FINAL: Accuracy=85.0%, Time=32s     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
   User completes: âœ“ 45s
```

**TASK 3: Averaging history**
```
â”Œâ”€ History Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ relevant_tasks = [âœ“30s, âœ“45s]      â”‚
â”‚ len = 2 â‰¤ 3 â†’ EARLY LEARNING!      â”‚
â”‚ recent_success_rate = 2/2 = 100%   â”‚
â”‚ recent_avg_time = (30+45)/2 = 37.5sâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€ Early Learning Adjustment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ success_rate = 100% â†’ prob = 85%    â”‚
â”‚ time = 37.5 * 1.05 = 39s            â”‚
â”‚ FINAL: Accuracy=85.0%, Time=39s     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
   User completes: âœ— 45s
```

**TASK 4: Exiting early learning**
```
â”Œâ”€ History Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ relevant_tasks = [âœ“30s, âœ“45s, âœ—45s]â”‚
â”‚ len = 3 â‰¤ 3 â†’ EARLY LEARNING!      â”‚
â”‚ recent_success_rate = 2/3 = 66.7%  â”‚
â”‚ recent_avg_time = (30+45+45)/3 = 40sâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€ Early Learning Adjustment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ success_rate = 66.7% â†’ prob = 65%   â”‚
â”‚ time = 40 * 1.05 = 42s              â”‚
â”‚ FINAL: Accuracy=65.0%, Time=42s     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
   User completes: âœ“ 30s
```

**KEY INSIGHT**: Early learning directly maps actual performance to predictions, providing **immediate adaptation** for first 3 tasks!

---

### ğŸ“Š SCENARIO 2: Experienced User (bulk) - Known Topic
**Topic**: Calculus (medium) - **HAS EXTENSIVE HISTORY**

**User Pattern**: âœ“30s, âœ—60s, âœ“45s, âœ“90s

#### Task-by-Task Breakdown:

**TASK 1: Using historical baseline**
```
â”Œâ”€ ML Prediction â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Analyzes bulk's Calculus history    â”‚
â”‚ (e.g., 50 completed tasks)          â”‚
â”‚ base_prob = 95% (high performer)    â”‚
â”‚ base_time = 126s (historical avg)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€ History Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ relevant_tasks = 50 past tasks      â”‚
â”‚ len = 50 > 3 â†’ NO EARLY LEARNING   â”‚
â”‚ recent_success_rate = ~95%          â”‚
â”‚ overall_success_rate = ~95%         â”‚
â”‚ success_improvement â‰ˆ 0             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€ Adaptive Adjustment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RULE 1: recent_success_rate > 0.8   â”‚
â”‚ â†’ Boost: 95% â†’ 95% (already at cap) â”‚
â”‚ RULE 3: No significant change neededâ”‚
â”‚ FINAL: Accuracy=95.0%, Time=126s    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
   User completes: âœ“ 30s (much faster!)
```

**TASK 2: Adapting to fast completion**
```
â”Œâ”€ ML Prediction â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ base_prob = 95%                     â”‚
â”‚ base_time = 126s                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€ History Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ relevant_tasks = [50 old + Task 1]  â”‚
â”‚ recent_n = 5 tasks                  â”‚
â”‚ recent_avg_time = ~100s (mixed)     â”‚
â”‚ overall_avg_time = ~120s            â”‚
â”‚ time_improvement = 120-100 = +20s   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€ RULE 3 Time Adjustment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ time_improvement = +20s > 10 âœ“      â”‚
â”‚ time_factor = 0.9 - (20/300)        â”‚
â”‚             = 0.9 - 0.067 = 0.833   â”‚
â”‚ adjusted = 126 * 0.833 = 105s       â”‚
â”‚                                     â”‚
â”‚ BUT ALSO: prediction_error check    â”‚
â”‚ base_time=126, recent_avg=30        â”‚
â”‚ prediction_error = 126-30 = 96s > 15â”‚
â”‚ 96/126 = 0.76 < 1.0 (not extreme)   â”‚
â”‚ blend_factor = 0.5 (capped)         â”‚
â”‚ adjusted = 126 * (1-0.5) = 63s      â”‚
â”‚                                     â”‚
â”‚ Takes more aggressive adjustment    â”‚
â”‚ FINAL: Accuracy=95.0%, Time=~13s    â”‚
â”‚ (actual may vary due to ML retrain) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
   User completes: âœ— 60s
```

**TASK 3: Accuracy stays high (one failure)**
```
â”Œâ”€ History Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ recent_success_rate = 4/5 = 80%     â”‚
â”‚ overall_success_rate = 49/52 = 94%  â”‚
â”‚ success_improvement = -14%          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€ RULE 1: High Performance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ recent = 80% > 0.7 âœ“                â”‚
â”‚ boost_factor = 1.15                 â”‚
â”‚ 95% * 1.15 = 109% â†’ capped at 95%   â”‚
â”‚ FINAL: Accuracy=95.0%, Time=~12s    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
   User completes: âœ“ 45s
```

**TASK 4: Mixed signals (correct but slow)**
```
â”Œâ”€ History Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Last 5: [âœ“30s, âœ—60s, âœ“45s, ?, ?]   â”‚
â”‚ recent_success_rate = 80%           â”‚
â”‚ recent_avg_time = (30+60+45)/3 = 45sâ”‚
â”‚ time_improvement = varied           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€ Adaptive Adjustment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Accuracy remains high ~95%          â”‚
â”‚ Time adapts to recent pattern ~12s  â”‚
â”‚ FINAL: Accuracy=95.0%, Time=12s     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
   User completes: âœ“ 90s
```

**KEY INSIGHT**: Experienced users have **stable accuracy predictions** (95% cap) but **time adapts** to recent patterns. The system balances historical performance with recent trends.

---

## Decision Tree Flowchart

```
START: Predict for new task
â”‚
â”œâ”€ Get ML Prediction (base_prob, base_time)
â”‚
â”œâ”€ Load relevant_tasks (same subject+topic+difficulty)
â”‚
â””â”€ Apply Adaptive Adjustment
   â”‚
   â”œâ”€ [len(relevant_tasks) â‰¤ 3] â†’ EARLY LEARNING
   â”‚   â”œâ”€ Map success_rate â†’ fixed accuracy tiers
   â”‚   â””â”€ time = recent_avg_time * 1.05
   â”‚
   â””â”€ [len(relevant_tasks) > 3] â†’ STANDARD RULES
       â”‚
       â”œâ”€ ACCURACY ADJUSTMENT
       â”‚   â”œâ”€ [recent_success > 0.8 AND improving > 0.1] â†’ RULE 1: High boost
       â”‚   â”œâ”€ [improving > 0.05] â†’ RULE 1: Moderate boost
       â”‚   â”œâ”€ [recent_success < 0.3 AND declining < -0.1] â†’ RULE 2: High reduction
       â”‚   â”œâ”€ [declining < -0.05] â†’ RULE 2: Moderate reduction
       â”‚   â”œâ”€ [recent_success < 0.2] â†’ RULE 2B: Floor at 15%
       â”‚   â””â”€ [tasks â‰¥ 10] â†’ RULE 4: Constrain unreasonable predictions
       â”‚
       â””â”€ TIME ADJUSTMENT (checks in order, first match wins)
           â”œâ”€ [time_improvement > 10s] â†’ RULE 3a: Reduce prediction
           â”œâ”€ [time_improvement < -10s] â†’ RULE 3b: Increase prediction
           â”œâ”€ [prediction_error > 15s] â†’ RULE 3c: Adjust toward actual
           â”‚   â”œâ”€ [deviation > 100%] â†’ Use actual * 1.05
           â”‚   â””â”€ [deviation â‰¤ 100%] â†’ Blend ML & actual
           â””â”€ [prediction_error < -15s] â†’ RULE 3d: Adjust toward actual
               â”œâ”€ [deviation > 100%] â†’ Use actual * 1.05
               â””â”€ [deviation â‰¤ 100%] â†’ Blend ML & actual

RETURN: (adjusted_prob, adjusted_time)
```

---

## Formulas & Calculations

### Time Improvement (Speed Change)
```python
time_improvement = overall_avg_time - recent_avg_time
# Positive = user getting FASTER
# Negative = user getting SLOWER
```

**Example**:
```
overall_avg_time = 60s (historical average)
recent_avg_time = 45s (last 5 tasks)
time_improvement = 60 - 45 = +15s (getting faster!)
```

### Prediction Error (ML vs Actual)
```python
prediction_error = base_time - recent_avg_time
# Positive = user FASTER than ML predicts
# Negative = user SLOWER than ML predicts
```

**Example**:
```
base_time = 60s (ML prediction)
recent_avg_time = 90s (actual performance)
prediction_error = 60 - 90 = -30s (slower than expected)
```

### Blend Factor (Extreme Deviation)
```python
if abs(prediction_error) / base_time > 1.0:
    # Deviation > 100% â†’ Use actual directly
    adjusted_time = recent_avg_time * 1.05
else:
    # Deviation â‰¤ 100% â†’ Blend ML and actual
    blend_factor = min(abs(prediction_error) / base_time, 0.5)
    if prediction_error > 0:  # Faster
        adjusted_time = base_time * (1 - blend_factor)
    else:  # Slower
        adjusted_time = base_time * (1 + blend_factor)
```

**Example - Extreme (>100%)**:
```
base_time = 60s
recent_avg_time = 150s
prediction_error = -90s
abs(-90) / 60 = 1.5 > 1.0 â†’ EXTREME
adjusted_time = 150 * 1.05 = 158s
```

**Example - Moderate (â‰¤100%)**:
```
base_time = 60s
recent_avg_time = 80s
prediction_error = -20s
abs(-20) / 60 = 0.33 â‰¤ 1.0 â†’ MODERATE
blend_factor = 0.33
adjusted_time = 60 * (1 + 0.33) = 80s
```

---

## Summary of Guaranteed Behaviors

âœ… **NEW USERS (First 3 tasks)**:
- Predictions adapt IMMEDIATELY to actual performance
- Accuracy: Direct mapping from success rate
- Time: recent_avg * 1.05

âœ… **EXPERIENCED USERS**:
- Predictions blend ML model with recent trends
- Accuracy: Capped at 95%, floored at 15%
- Time: Adapts to speed changes and deviation from ML

âœ… **EXTREME DEVIATIONS (>100%)**:
- System trusts actual performance over ML
- Uses recent_avg_time * 1.05 directly

âœ… **CONSISTENCY**:
- Same topic + difficulty + subject â†’ Same prediction rules
- No random variation, fully deterministic

---

**Generated**: 2025-11-11
**System Version**: v2.0 (with extreme deviation handling)
